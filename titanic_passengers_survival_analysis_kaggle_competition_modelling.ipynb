{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## 4. Prepare the data\n",
    "\n",
    "We will now prepare the data for machine learning modelling.\n",
    "\n",
    "Let's start by separating the predictors and labels since we do not want to apply the same transformations to both."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "titanic_pred = titanic_train.drop(\"Survived\", axis=1)\n",
    "titanic_labels = titanic_train[\"Survived\"].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 891 entries, 1 to 891\n",
      "Data columns (total 10 columns):\n",
      "Pclass      891 non-null int64\n",
      "Name        891 non-null object\n",
      "Sex         891 non-null object\n",
      "Age         714 non-null float64\n",
      "SibSp       891 non-null int64\n",
      "Parch       891 non-null int64\n",
      "Ticket      891 non-null object\n",
      "Fare        891 non-null float64\n",
      "Cabin       204 non-null object\n",
      "Embarked    889 non-null object\n",
      "dtypes: float64(2), int64(3), object(5)\n",
      "memory usage: 76.6+ KB\n"
     ]
    }
   ],
   "source": [
    "titanic_pred.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Two attributes seems to be meaningles for machine learning model are `PassengerId` and `Name` which is why let's drop this column. As we have seen earlier analysing text attributes unique values also `Ticket` attribute seems to be meaningless so we also drop its values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "titanic_pred = titanic_pred.drop([\"Name\", \"Ticket\"], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 891 entries, 1 to 891\n",
      "Data columns (total 8 columns):\n",
      "Pclass      891 non-null int64\n",
      "Sex         891 non-null object\n",
      "Age         714 non-null float64\n",
      "SibSp       891 non-null int64\n",
      "Parch       891 non-null int64\n",
      "Fare        891 non-null float64\n",
      "Cabin       204 non-null object\n",
      "Embarked    889 non-null object\n",
      "dtypes: float64(2), int64(3), object(3)\n",
      "memory usage: 62.6+ KB\n"
     ]
    }
   ],
   "source": [
    "titanic_pred.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we need to deal with missing values we found in the dataset. \n",
    "\n",
    "Again the most missing value are in `Cabin` column. That column seems not so much informative and the data if rather scarse which would suggesting droping this feature from the training data set. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "titanic_pred = titanic_pred.drop(\"Cabin\", axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In `Embarked` column features we miss only two values so we can easily drop these two cases."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "indexes_to_drop = titanic_pred[titanic_pred[\"Embarked\"].isnull()].index.values\n",
    "titanic_pred = titanic_pred.drop(indexes_to_drop, axis=0)\n",
    "titanic_labels = titanic_labels.drop(indexes_to_drop, axis=0)\n",
    "titanic_pred = titanic_pred.reset_index(drop=True)\n",
    "titanic_labels = titanic_labels.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "We have also a lot of missing values in `Age` column however this column seems crucial for our analysis. As starter we decide to fill missing values with median value. Other option is to throw away passengers with missing `Age` value, but considering that it is over 80  passengers data record we would like not to do it. \n",
    "\n",
    "Median can only be computed on numerical attributes, so we need to make a copy of the data - one containing only numerical data and one containing only categorical data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "titanic_pred_num = titanic_pred.drop([\"Sex\", \"Embarked\"], axis=1)\n",
    "titanic_pred_cat = titanic_pred[[\"Sex\", \"Embarked\"]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have now only 2 categorical attributes since we dropped `Name` (meaningless), `Cabin` (to many missing values) and `Ticket` (meaningless) attributes.\n",
    "\n",
    "Let's now use Scikit-Learn Imputer class to fill `Age` attribute missing values and to standardize all values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import Imputer \n",
    "\n",
    "num_pipeline = Pipeline([\n",
    "    ('imputer', Imputer(strategy=\"median\")),\n",
    "#     ('std_scaler', StandardScaler()),\n",
    "])\n",
    "titanic_pred_num_prepared = num_pipeline.fit_transform(titanic_pred_num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  3.    ,  22.    ,   1.    ,   0.    ,   7.25  ],\n",
       "       [  1.    ,  38.    ,   1.    ,   0.    ,  71.2833],\n",
       "       [  3.    ,  26.    ,   0.    ,   0.    ,   7.925 ],\n",
       "       ..., \n",
       "       [  3.    ,  28.    ,   1.    ,   2.    ,  23.45  ],\n",
       "       [  1.    ,  26.    ,   0.    ,   0.    ,  30.    ],\n",
       "       [  3.    ,  32.    ,   0.    ,   0.    ,   7.75  ]])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "titanic_pred_num_prepared"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have all our numerical attributes ready to go.\n",
    "\n",
    "Let's now take care of out categorical attributes values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 889 entries, 0 to 888\n",
      "Data columns (total 2 columns):\n",
      "Sex         889 non-null object\n",
      "Embarked    889 non-null object\n",
      "dtypes: object(2)\n",
      "memory usage: 14.0+ KB\n"
     ]
    }
   ],
   "source": [
    "titanic_pred_cat.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since most machine learning algorithms do not deal with text data so well let's convert text labels we have to numbers. We will use one-hot encoding for this job. First we will convert our attributes from text categories to integer categories, then from integer categories to one-hot vectors using the LabelBinarizer class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelBinarizer\n",
    "encoder = LabelBinarizer()\n",
    "titanic_pred_cat_sex_1hot = encoder.fit_transform(titanic_pred_cat[\"Sex\"])\n",
    "encoder = LabelBinarizer()\n",
    "titanic_pred_cat_embarked_1hot = encoder.fit_transform(titanic_pred_cat[\"Embarked\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now have all our data prepared. The last thing is to combine it again into one data set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "titanic_pred_prepared = np.concatenate([titanic_pred_num_prepared, titanic_pred_cat_sex_1hot, titanic_pred_cat_embarked_1hot], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Short-list promising models\n",
    "\n",
    "Our data is prepared so we are ready to fit multiple quick models to check how they behave. Our measure of success is classification accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log_clf = LogisticRegression()\n",
    "log_clf.fit(titanic_pred_prepared, titanic_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will test our model using cross-validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.79124579,  0.79054054,  0.78378378])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "cross_val_score(log_clf, titanic_pred_prepared, titanic_labels, cv=3, scoring=\"accuracy\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's try Stochastic Gradient Descent classifier using Scikit-Learn's SGDClassifier class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SGDClassifier(alpha=0.0001, average=False, class_weight=None, epsilon=0.1,\n",
       "       eta0=0.0, fit_intercept=True, l1_ratio=0.15,\n",
       "       learning_rate='optimal', loss='hinge', n_iter=5, n_jobs=1,\n",
       "       penalty='l2', power_t=0.5, random_state=42, shuffle=True, verbose=0,\n",
       "       warm_start=False)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import SGDClassifier\n",
    "\n",
    "sgd_clf = SGDClassifier(random_state=42)\n",
    "sgd_clf.fit(titanic_pred_prepared, titanic_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's now use cross-validation to validate our model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.62626263,  0.7027027 ,  0.72635135])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "cross_val_score(sgd_clf, titanic_pred_prepared, titanic_labels, cv=3, scoring=\"accuracy\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Another model will be K-Nearest Neighbors classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
       "           metric_params=None, n_jobs=1, n_neighbors=5, p=2,\n",
       "           weights='uniform')"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "knn_clf = KNeighborsClassifier()\n",
    "knn_clf.fit(titanic_pred_prepared, titanic_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.68686869,  0.71283784,  0.71621622])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cross_val_score(knn_clf, titanic_pred_prepared, titanic_labels, cv=3, scoring=\"accuracy\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So far the best results we got from Logistic Regression model. Let's try different polynomials versions of it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "polynomial_features_2 = PolynomialFeatures(degree=2, include_bias=False)\n",
    "polynomial_features_4 = PolynomialFeatures(degree=4, include_bias=False)\n",
    "polynomial_features_8 = PolynomialFeatures(degree=8, include_bias=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "titanic_pred_prepared_poly_2 = polynomial_features_2.fit_transform(titanic_pred_prepared)\n",
    "titanic_pred_prepared_poly_4 = polynomial_features_4.fit_transform(titanic_pred_prepared)\n",
    "titanic_pred_prepared_poly_8 = polynomial_features_8.fit_transform(titanic_pred_prepared)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(889, 9)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "titanic_pred_prepared.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(889, 54)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "titanic_pred_prepared_poly_2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(889, 714)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "titanic_pred_prepared_poly_4.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(889, 24309)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "titanic_pred_prepared_poly_8.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.80808081,  0.81418919,  0.81418919])"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log_clf_2 = LogisticRegression()\n",
    "log_clf_2.fit(titanic_pred_prepared_poly_2, titanic_labels)\n",
    "cross_val_score(log_clf_2, titanic_pred_prepared_poly_2, titanic_labels, cv=3, scoring=\"accuracy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.7037037 ,  0.72635135,  0.71283784])"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log_clf_4 = LogisticRegression()\n",
    "log_clf_4.fit(titanic_pred_prepared_poly_4, titanic_labels)\n",
    "cross_val_score(log_clf_4, titanic_pred_prepared_poly_4, titanic_labels, cv=3, scoring=\"accuracy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.63973064,  0.61486486,  0.67567568])"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log_clf_8 = LogisticRegression()\n",
    "log_clf_8.fit(titanic_pred_prepared_poly_8, titanic_labels)\n",
    "cross_val_score(log_clf_8, titanic_pred_prepared_poly_8, titanic_labels, cv=3, scoring=\"accuracy\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So using square polynomial features and logistic regression model improves results a bit. Using higher degree polynomials lower accuracy result.\n",
    "\n",
    "TODO: Check why higher degree polynomial lowers accuracy result in cross-validation. Visualize how the decision boundary looks like."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's try another - more complex - model. Now we will use Random Forest classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.76430976,  0.79391892,  0.80067568])"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "forest_clf = RandomForestClassifier()\n",
    "forest_clf.fit(titanic_pred_prepared, titanic_labels)\n",
    "cross_val_score(forest_clf, titanic_pred_prepared, titanic_labels, cv=3, scoring=\"accuracy\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "No we reached a little bit better accuracy in our model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('scaler', StandardScaler(copy=True, with_mean=True, with_std=True)), ('linear_svc', LinearSVC(C=1, class_weight=None, dual=True, fit_intercept=True,\n",
       "     intercept_scaling=1, loss='hinge', max_iter=1000, multi_class='ovr',\n",
       "     penalty='l2', random_state=None, tol=0.0001, verbose=0))])"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.svm import LinearSVC\n",
    "\n",
    "svm_clf = Pipeline([\n",
    "        (\"scaler\", StandardScaler()),\n",
    "        (\"linear_svc\", LinearSVC(C=1, loss=\"hinge\")),\n",
    "    ])\n",
    "svm_clf.fit(titanic_pred_prepared, titanic_labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.75420875,  0.80405405,  0.78716216])"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "poly_kernel_svm_clf = Pipeline((\n",
    "        (\"scaler\", StandardScaler()),\n",
    "        (\"svm_clf\", SVC(kernel=\"poly\", degree=6, coef0=1, C=5))\n",
    "))\n",
    "poly_kernel_svm_clf.fit(titanic_pred_prepared, titanic_labels)\n",
    "cross_val_score(poly_kernel_svm_clf, titanic_pred_prepared, titanic_labels, cv=3, scoring=\"accuracy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.61616162,  0.61824324,  0.61824324])"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "rbf_kernel_svm_clf = Pipeline((\n",
    "        (\"scaler\", StandardScaler()),\n",
    "        (\"svm_clf\", SVC(kernel=\"rbf\", gamma=5, C=0.001))\n",
    "))\n",
    "rbf_kernel_svm_clf.fit(titanic_pred_prepared, titanic_labels)\n",
    "cross_val_score(rbf_kernel_svm_clf, titanic_pred_prepared, titanic_labels, cv=3, scoring=\"accuracy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Fine-tune models\n",
    "\n",
    "We have two promissing models. Let's try to improve their performance by fine-tuning their parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Submit solution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "titanic_test = pd.read_csv(\"datasets/test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "titanic_test = titanic_test.drop([\"PassengerId\", \"Name\", \"Ticket\"], axis=1)\n",
    "titanic_test = titanic_test.drop(\"Cabin\", axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "titanic_test_num = titanic_test.drop([\"Sex\", \"Embarked\"], axis=1)\n",
    "titanic_test_cat = titanic_test[[\"Sex\", \"Embarked\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 418 entries, 0 to 417\n",
      "Data columns (total 5 columns):\n",
      "Pclass    418 non-null int64\n",
      "Age       332 non-null float64\n",
      "SibSp     418 non-null int64\n",
      "Parch     418 non-null int64\n",
      "Fare      417 non-null float64\n",
      "dtypes: float64(2), int64(3)\n",
      "memory usage: 16.4 KB\n"
     ]
    }
   ],
   "source": [
    "titanic_test_num.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "imputer = Imputer(strategy=\"median\")\n",
    "imputer.fit(titanic_test_num)\n",
    "titanic_test_num_prepared = imputer.transform(titanic_test_num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 418 entries, 0 to 417\n",
      "Data columns (total 2 columns):\n",
      "Sex         418 non-null object\n",
      "Embarked    418 non-null object\n",
      "dtypes: object(2)\n",
      "memory usage: 6.6+ KB\n"
     ]
    }
   ],
   "source": [
    "titanic_test_cat.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "encoder = LabelBinarizer()\n",
    "titanic_test_cat_sex_1hot = encoder.fit_transform(titanic_test_cat[\"Sex\"])\n",
    "encoder = LabelBinarizer()\n",
    "titanic_test_cat_embarked_1hot = encoder.fit_transform(titanic_test_cat[\"Embarked\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "titanic_test_prepared = np.concatenate([titanic_test_num_prepared, titanic_test_cat_sex_1hot, titanic_test_cat_embarked_1hot], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "final_predictions = forest_clf.predict(titanic_test_prepared)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "final_df = pd.DataFrame({'PassengerId': range(892, len(final_predictions)+892), 'Survived': final_predictions})\n",
    "final_df.to_csv(\"datasets/submission.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Your submission scored 0.73205 (position 8732)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
